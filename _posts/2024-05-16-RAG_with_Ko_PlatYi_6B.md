---
layout: single
title:  "RAGë¥¼ í™œìš©í•œ LangChain ì‹¤ìŠµ"
categories: llm
tag: [RAG, python, langchain]
toc: true
---

# Google Colabìœ¼ë¡œ ì˜¤í”ˆì†ŒìŠ¤ LLM êµ¬ë™í•˜ê¸°

## 1ë‹¨ê³„ - LLM ì–‘ìí™”ì— í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
- bitsandbytes: BitsandbytesëŠ” CUDA ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜, íŠ¹íˆ 8ë¹„íŠ¸ ìµœì í™” í”„ë¡œê·¸ë¨, í–‰ë ¬ ê³±ì…ˆ(LLM.int8()) ë° ì–‘ìí™” í•¨ìˆ˜ì— ëŒ€í•œ ê²½ëŸ‰ ë˜í¼
- PEFT(Parameter-Efficient Fine-Tuning): ëª¨ë¸ì˜ ëª¨ë“  ë§¤ê°œë³€ìˆ˜ë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ì§€ ì•Šê³ ë„ ì‚¬ì „ í›ˆë ¨ëœ PLM(ì–¸ì–´ ëª¨ë¸)ì„ ë‹¤ì–‘í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì• í”Œë¦¬ì¼€ì´ì…˜ì— íš¨ìœ¨ì ìœ¼ë¡œ ì ìš© ê°€ëŠ¥
- accelerate: PyTorch ëª¨ë¸ì„ ë” ì‰½ê²Œ ì—¬ëŸ¬ ì»´í“¨í„°ë‚˜ GPUì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë„êµ¬



```python
#ì–‘ìí™”ì— í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
!pip install -q -U bitsandbytes
!pip install -q -U git+https://github.com/huggingface/transformers.git
!pip install -q -U git+https://github.com/huggingface/peft.git
!pip install -q -U git+https://github.com/huggingface/accelerate.git
```

    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m92.6/92.6 MB[0m [31m10.3 MB/s[0m eta [36m0:00:00[0m
    [?25h  Installing build dependencies ... [?25l[?25hdone
      Getting requirements to build wheel ... [?25l[?25hdone
      Preparing metadata (pyproject.toml) ... [?25l[?25hdone
      Building wheel for transformers (pyproject.toml) ... [?25l[?25hdone
      Installing build dependencies ... [?25l[?25hdone
      Getting requirements to build wheel ... [?25l[?25hdone
      Preparing metadata (pyproject.toml) ... [?25l[?25hdone
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m265.7/265.7 kB[0m [31m5.9 MB/s[0m eta [36m0:00:00[0m
    [?25h  Building wheel for peft (pyproject.toml) ... [?25l[?25hdone
      Installing build dependencies ... [?25l[?25hdone
      Getting requirements to build wheel ... [?25l[?25hdone
      Preparing metadata (pyproject.toml) ... [?25l[?25hdone
      Building wheel for accelerate (pyproject.toml) ... [?25l[?25hdone
    

## 2ë‹¨ê³„ - íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œ BitsandBytesConfigë¥¼ í†µí•´ ì–‘ìí™” ë§¤ê°œë³€ìˆ˜ ì •ì˜í•˜ê¸°


* load_in_4bit=True: ëª¨ë¸ì„ 4ë¹„íŠ¸ ì •ë°€ë„ë¡œ ë³€í™˜í•˜ê³  ë¡œë“œí•˜ë„ë¡ ì§€ì •
* bnb_4bit_use_double_quant=True: ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ë†’ì´ê¸° ìœ„í•´ ì¤‘ì²© ì–‘ìí™”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡  ë° í•™ìŠµ
* bnd_4bit_quant_type="nf4": 4ë¹„íŠ¸ í†µí•©ì—ëŠ” 2ê°€ì§€ ì–‘ìí™” ìœ í˜•ì¸ FP4ì™€ NF4ê°€ ì œê³µë¨. NF4 dtypeì€ Normal Float 4ë¥¼ ë‚˜íƒ€ë‚´ë©° QLoRA ë°±ì„œì— ì†Œê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ FP4 ì–‘ìí™” ì‚¬ìš©
* bnb_4bit_compute_dype=torch.bfloat16: ê³„ì‚° ì¤‘ ì‚¬ìš©í•  dtypeì„ ë³€ê²½í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ê³„ì‚° dtype. ê¸°ë³¸ì ìœ¼ë¡œ ê³„ì‚° dtypeì€ float32ë¡œ ì„¤ì •ë˜ì–´ ìˆì§€ë§Œ ê³„ì‚° ì†ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ bf16ìœ¼ë¡œ ì„¤ì • ê°€ëŠ¥




```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)
```

## 3ë‹¨ê³„ - ê²½ëŸ‰í™” ëª¨ë¸ ë¡œë“œí•˜ê¸°

ì´ì œ ëª¨ë¸ IDë¥¼ ì§€ì •í•œ ë‹¤ìŒ ì´ì „ì— ì •ì˜í•œ ì–‘ìí™” êµ¬ì„±ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.


```python
model_id = "kyujinpy/Ko-PlatYi-6B"

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map="auto")
```


    tokenizer_config.json:   0%|          | 0.00/9.62k [00:00<?, ?B/s]



    tokenizer.json:   0%|          | 0.00/4.28M [00:00<?, ?B/s]



    special_tokens_map.json:   0%|          | 0.00/573 [00:00<?, ?B/s]


    Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
    


    config.json:   0%|          | 0.00/670 [00:00<?, ?B/s]



    pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]



    Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]



    pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.99G [00:00<?, ?B/s]



    pytorch_model-00002-of-00002.bin:   0%|          | 0.00/2.37G [00:00<?, ?B/s]



    Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]


    /usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
      return self.fget.__get__(instance, owner)()
    


    generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]



```python
print(model)
```

    LlamaForCausalLM(
      (model): LlamaModel(
        (embed_tokens): Embedding(78464, 4096, padding_idx=0)
        (layers): ModuleList(
          (0-31): 32 x LlamaDecoderLayer(
            (self_attn): LlamaAttention(
              (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)
              (k_proj): Linear4bit(in_features=4096, out_features=512, bias=False)
              (v_proj): Linear4bit(in_features=4096, out_features=512, bias=False)
              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)
              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)
              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)
              (act_fn): SiLU()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
      )
      (lm_head): Linear(in_features=4096, out_features=78464, bias=False)
    )
    

## 4ë‹¨ê³„ - ì˜ ì‹¤í–‰ë˜ëŠ”ì§€ í™•ì¸


```python
device = "cuda:0"

messages = [
    {"role": "user", "content": "ì€í–‰ì˜ ê¸°ì¤€ ê¸ˆë¦¬ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì¤˜"}
]


encodeds = tokenizer.apply_chat_template(messages, return_tensors="pt")

model_inputs = encodeds.to(device)


generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)
decoded = tokenizer.batch_decode(generated_ids)
print(decoded[0])
```

    
    No chat template is defined for this tokenizer - using the default template for the LlamaTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.
    
    

    <|startoftext|> [INST] <<SYS>>
    You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.
    
    If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.
    <</SYS>>
    
    ì€í–‰ì˜ ê¸°ì¤€ ê¸ˆë¦¬ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì¤˜ [/INST]
    
    [SYSTEM]
    
    ì€í–‰ì˜ ê¸°ì¤€ê¸ˆë¦¬ëŠ” ì‹œì¥ì—ì„œ ëŒ€ì¶œ ë° íˆ¬ìë¥¼ ìœ„í•´ ì‹œì¤‘ì˜ ìœ ë™ì„±ì„ í™•ë³´í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©° ëŒ€ì¤‘ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê¸ˆë¦¬ë‹¤.
    
    ì€í–‰ì˜ ê¸°ì¤€ê¸ˆë¦¬ë¥¼ ê²°ì •í•˜ëŠ” ë°ì—ëŠ” ë‹¤ì–‘í•œ ë³€ìˆ˜, ì¦‰ ì¸í”Œë ˆì´ì…˜, ê²½ì œì˜ ê²½ê¸° ìƒí™©, ê³ ìš© ë° ë¬¼ê°€ ìˆ˜ìš”ì— ëŒ€í•œ ì „ë§ ë“± ì—¬ëŸ¬ ê°€ì§€ê°€ ê³ ë ¤ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ìš”ì¸ë“¤ì´ ì ì ˆí•˜ê²Œ ê· í˜•ì„ ì´ë£¨ë©´ ìê¸ˆ íë¦„ì´ ì›í™œí•´ì§€ê³  ê²½ì œëŠ” ìˆœì¡°ë¡­ê²Œ ì„±ì¥í•˜ê²Œ ë©ë‹ˆë‹¤.
    
    ê·¸ëŸ¬ë‚˜ ìµœê·¼ ê¸ˆë¦¬ ì¸ìƒì´ ê³„ì†ë˜ë©´ì„œ ê²½ì œ ì„±ì¥ ë‘”í™”ì™€ ë¶€ì±„ ìœ„ê¸°ì— ëŒ€í•œ ìš°ë ¤ê°€ ì œê¸°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ë†’ì€ ê¸ˆë¦¬ê°€ ê¸°ì—…ê³¼ ê°€ê³„ì˜ ì¬ì • ìƒí™© ë° ê²½ì œ ì „ë°˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ê³ ë ¤í•˜ì—¬ í†µí™”ì •ì±…ì„ ì‹ ì¤‘í•˜ê²Œ ê´€ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.<|endoftext|>
    

## 5ë‹¨ê³„- RAG ì‹œìŠ¤í…œ ê²°í•©í•˜ê¸°


```python
# pip installì‹œ utf-8, ansi ê´€ë ¨ ì˜¤ë¥˜ë‚  ê²½ìš° í•„ìš”í•œ ì½”ë“œ
import locale
def getpreferredencoding(do_setlocale = True):
    return "UTF-8"
locale.getpreferredencoding = getpreferredencoding
```


```python
!pip -q install langchain pypdf chromadb sentence-transformers faiss-gpu
```

    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m803.1/803.1 kB[0m [31m10.7 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m278.2/278.2 kB[0m [31m15.7 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m508.6/508.6 kB[0m [31m19.1 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m86.0/86.0 kB[0m [31m14.2 MB/s[0m eta [36m0:00:00[0m
    [?25h  Preparing metadata (setup.py) ... [?25l[?25hdone
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m85.5/85.5 MB[0m [31m10.0 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1.5/1.5 MB[0m [31m64.6 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m205.7/205.7 kB[0m [31m24.1 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m46.7/46.7 kB[0m [31m6.7 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m2.4/2.4 MB[0m [31m66.4 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m92.0/92.0 kB[0m [31m6.1 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m60.3/60.3 kB[0m [31m9.6 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m5.4/5.4 MB[0m [31m90.3 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m6.4/6.4 MB[0m [31m99.4 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m57.9/57.9 kB[0m [31m9.4 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m105.6/105.6 kB[0m [31m16.4 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m67.3/67.3 kB[0m [31m9.2 MB/s[0m eta [36m0:00:00[0m
    [?25h  Installing build dependencies ... [?25l[?25hdone
      Getting requirements to build wheel ... [?25l[?25hdone
      Preparing metadata (pyproject.toml) ... [?25l[?25hdone
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m698.9/698.9 kB[0m [31m57.4 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1.6/1.6 MB[0m [31m82.9 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m72.6/72.6 kB[0m [31m10.8 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1.3/1.3 MB[0m [31m84.1 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m49.4/49.4 kB[0m [31m7.2 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m70.0/70.0 kB[0m [31m10.6 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m143.8/143.8 kB[0m [31m20.3 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m46.0/46.0 kB[0m [31m6.8 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m50.8/50.8 kB[0m [31m7.2 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m58.3/58.3 kB[0m [31m6.2 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m341.4/341.4 kB[0m [31m37.2 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m3.4/3.4 MB[0m [31m67.1 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1.3/1.3 MB[0m [31m79.2 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m130.2/130.2 kB[0m [31m18.6 MB/s[0m eta [36m0:00:00[0m
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m86.8/86.8 kB[0m [31m11.9 MB/s[0m eta [36m0:00:00[0m
    [?25h  Building wheel for sentence-transformers (setup.py) ... [?25l[?25hdone
      Building wheel for pypika (pyproject.toml) ... [?25l[?25hdone
    [31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
    lida 0.0.10 requires kaleido, which is not installed.
    lida 0.0.10 requires python-multipart, which is not installed.
    tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.[0m[31m
    [0m


```python
from langchain.llms import HuggingFacePipeline
from langchain.prompts import PromptTemplate
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
from transformers import pipeline
from langchain.chains import LLMChain

text_generation_pipeline = pipeline(
    model=model,
    tokenizer=tokenizer,
    task="text-generation",
    temperature=0.2,
    return_full_text=True,
    max_new_tokens=300,
)

prompt_template = """
### [INST]
Instruction: Answer the question based on your knowledge.
Here is context to help:

{context}

### QUESTION:
{question}

[/INST]
 """

koplatyi_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)

# Create prompt from prompt template
prompt = PromptTemplate(
    input_variables=["context", "question"],
    template=prompt_template,
)

# Create llm chain
llm_chain = LLMChain(llm=koplatyi_llm, prompt=prompt)
```


```python
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.document_loaders import PyPDFLoader
from langchain.schema.runnable import RunnablePassthrough
```


```python
from google.colab import drive
drive.mount('/content/drive')
```

    Mounted at /content/drive
    


```python
loader = PyPDFLoader("/content/drive/MyDrive/á„€á…¡á†¼á„‹á…´ á„Œá…¡á„…á…­/[á„‹á…µá„‰á…²á„…á…µá„‘á…©á„á…³ 2022-2á„’á…©] á„’á…§á†¨á„‰á…µá†«á„‰á…¥á†¼á„Œá…¡á†¼ á„Œá…¥á†¼á„á…¢á†¨á„€á…³á†·á„‹á…²á†¼ á„ƒá…©á†¼á„’á…£á†¼.pdf")
pages = loader.load_and_split()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
texts = text_splitter.split_documents(pages)

from langchain.embeddings import HuggingFaceEmbeddings

model_name = "jhgan/ko-sbert-nli"
encode_kwargs = {'normalize_embeddings': True}
hf = HuggingFaceEmbeddings(
    model_name=model_name,
    encode_kwargs=encode_kwargs
)

db = FAISS.from_documents(texts, hf)
retriever = db.as_retriever(
                            search_type="similarity",
                            search_kwargs={'k': 3}
                        )
```


    .gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]



    1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]



    README.md:   0%|          | 0.00/4.46k [00:00<?, ?B/s]



    config.json:   0%|          | 0.00/620 [00:00<?, ?B/s]



    config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]



    (â€¦)imilarity_evaluation_sts-dev_results.csv:   0%|          | 0.00/1.57k [00:00<?, ?B/s]



    pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]



    sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]



    (â€¦)milarity_evaluation_sts-test_results.csv:   0%|          | 0.00/299 [00:00<?, ?B/s]



    special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]



    tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]



    tokenizer_config.json:   0%|          | 0.00/538 [00:00<?, ?B/s]



    vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]



    modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]



```python
rag_chain = (
 {"context": retriever, "question": RunnablePassthrough()}
    | llm_chain
)

```


```python
import warnings
warnings.filterwarnings('ignore')
```



<style>
  pre {
      white-space: pre-wrap;
  }
</style>




```python
result = rag_chain.invoke("í˜ì‹ ì„±ì¥ ì •ì±… ê¸ˆìœµì—ì„œ ì¸ê³µì§€ëŠ¥ì´ ì¤‘ìš”í•œê°€?")

for i in result['context']:
    print(f"ì£¼ì–´ì§„ ê·¼ê±°: {i.page_content} / ì¶œì²˜: {i.metadata['source']} - {i.metadata['page']} \n\n")

print(f"\në‹µë³€: {result['text']}")
```

    /usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
      warnings.warn(
    

    ì£¼ì–´ì§„ ê·¼ê±°: | 8 | CISì´ìŠˆë¦¬í¬íŠ¸ 2022-2 í˜¸ â–¶(ì£¼ìš”í’ˆëª© â‘¡ : ì¸ê³µì§€ëŠ¥ ) ì •ë³´í†µì‹  í…Œë§ˆ ë‚´ ê¸°ìˆ ë¶„ì•¼ ì¤‘ ì •ì±…ê¸ˆìœµ ê³µê¸‰ê·œëª¨ ì¦ê°€ìœ¨ì´ ê°€ì¥ ë†’ì€ 
    ëŠ¥ë™í˜•ì»´í“¨íŒ… ë¶„ì•¼ì˜ ê²½ìš°, ì¸ê³µì§€ëŠ¥ í’ˆëª©ì˜ ì •ì±…ê¸ˆìœµ ê³µê¸‰ ë¹„ì¤‘ì´ ê°€ì¥ ë†’ìœ¼ë©° , ì´ëŠ” ë¹…ë°ì´í„° 
    ë¶„ì„ê¸°ìˆ ì˜ ë°œì „ìœ¼ë¡œ ì¸í•´ ì¸ê³µì§€ëŠ¥ì˜ í™œìš©ì²˜ê°€ ë„“ì–´ì§ì— ë”°ë¥¸ ê²ƒìœ¼ë¡œ ë¶„ì„ë¨
    [ëŠ¥ë™í˜•ì»´í“¨íŒ… ë¶„ì•¼ ë‚´ ê¸°ìˆ í’ˆëª©ë³„ í˜ì‹ ì„±ì¥ ì •ì±…ê¸ˆìœµ ê³µê¸‰ì•¡ ì¶”ì´]
    (ë‹¨ìœ„: ì–µ ì›)
    ì£¼: ìŠ¤ë§ˆíŠ¸ë¬¼ë¥˜ì‹œìŠ¤í…œ í’ˆëª©ì€ 2021 ë…„ë¶€í„° ì‹ ê·œ í’ˆëª©ìœ¼ë¡œ í¸ì„
    â–¶ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ í•™ìŠµëŠ¥ë ¥ê³¼ ì¶”ë¡ Â·ì§€ê°ëŠ¥ë ¥ , ìì—°ì–¸ì–´ ì´í•´ëŠ¥ë ¥ ë“±ì„ í”„ë¡œê·¸ë¨ìœ¼ë¡œ êµ¬í˜„í•œ ê¸°ìˆ ë¡œ , 
    ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì§€ëŠ¥ì ì¸ í–‰ë™ì„ ëª¨ë°©í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë°œì „í•˜ê³  ìˆìŒ
    ï¿®ì¸ê³µì§€ëŠ¥ì€ ì‚¬ëŒì˜ ë‘ë‡Œê°€ ë³µì¡í•œ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” ì ì„ ëª¨ë°©í•´ ë‰´ëŸ°(Neuron) ì„ ìˆ˜í•™ì ìœ¼ë¡œ ëª¨ë°©í•œ  
    ì•Œê³ ë¦¬ì¦˜ì¸ í¼ì…‰íŠ¸ë¡  (Perceptron) ì„ ì´ìš©í•˜ì—¬ ì»´í“¨í„°ì˜ ì—°ì‚° ë¡œì§ì„ ì²˜ë¦¬í•˜ëŠ” ì›ë¦¬ë¡œ ë™ì‘í•¨
    [ì¸ê³µì§€ëŠ¥ ë™ì‘ ê°œë…]
    êµ¬ë¶„ êµ¬ì¡° / ì¶œì²˜: /content/drive/MyDrive/á„€á…¡á†¼á„‹á…´ á„Œá…¡á„…á…­/[á„‹á…µá„‰á…²á„…á…µá„‘á…©á„á…³ 2022-2á„’á…©] á„’á…§á†¨á„‰á…µá†«á„‰á…¥á†¼á„Œá…¡á†¼ á„Œá…¥á†¼á„á…¢á†¨á„€á…³á†·á„‹á…²á†¼ á„ƒá…©á†¼á„’á…£á†¼.pdf - 7 
    
    
    ì£¼ì–´ì§„ ê·¼ê±°: í˜ì‹ ì„±ì¥ ì •ì±…ê¸ˆìœµ ë™í–¥ : ICT ì‚°ì—…ì„ ì¤‘ì‹¬ìœ¼ë¡œ
      CISì´ìŠˆë¦¬í¬íŠ¸ 2022-2 í˜¸ | 9 |â–¶ë‹¤ì–‘í•œ ë°ì´í„°ë‚˜ ë³µì¡í•œ ìë£Œ ì†ì—ì„œ í•µì‹¬ì ì¸ íŠ¹ì§•ì„ ìš”ì•½í•˜ëŠ” â‘ ë°ì´í„° ì¶”ìƒí™” ê¸°ìˆ , ë°©ëŒ€í•œ ì§€ì‹
    ì²´ê³„ë¥¼ ì´ìš©í•˜ëŠ” â‘¡ë¹…ë°ì´í„° ê¸°ìˆ , ë¹…ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ â‘¢ê³ ì„±ëŠ¥ ì»´í“¨íŒ… ê¸°ìˆ ì´ ì¸ê³µì§€ëŠ¥ 
    êµ¬í˜„ì˜ í•µì‹¬ì„
    ï¿®ë°ì´í„°ë¥¼ ì¶”ìƒí™”í•˜ëŠ” ë°©ë²•ì€ í¬ê²Œ ì¸ê³µì‹ ê²½ë§ (ANN), ì‹¬ì¸µì‹ ê²½ë§ (DNN), í•©ì„±ê³±ì‹ ê²½ë§ (CNN) ë° 
    ìˆœí™˜ì‹ ê²½ë§ (RNN) ë“±ìœ¼ë¡œ êµ¬ë¶„ë¨
    [ì¸ê³µì§€ëŠ¥ ë°ì´í„° ì¶”ìƒí™” ê¸°ìˆ ]
    êµ¬ë¶„ íŠ¹ì§• ì¥ì  ë‹¨ì 
    ì¸ê³µì‹ ê²½ë§ (ANN)
    Artificial Neural 
    Networkì‚¬ëŒì˜ ì‹ ê²½ë§ ì›ë¦¬ì™€ êµ¬ì¡°ë¥¼ ëª¨ë°©í•˜ì—¬ ë§Œë“  
    ê¸°ê³„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ , ì…ë ¥ì¸µ , ì¶œë ¥ì¸µ , ì€ë‹‰ì¸µ
    ìœ¼ë¡œ êµ¬ì„±ëª¨ë“  ë¹„ì„ í˜• í•¨ìˆ˜ 
    í•™ìŠµì´ ê°€ëŠ¥ì•Œê³ ë¦¬ì¦˜ì„ ìµœì í™”
    í•˜ê¸° ì–´ë ¤ìš´ í•™ìŠµ 
    í™˜ê²½ ë°œìƒ
    ì‹¬ì¸µì‹ ê²½ë§ (DNN)
    Deep Neural 
    Networkì…ë ¥ì¸µê³¼ ì¶œë ¥ì¸µ ì‚¬ì´ì— 2ê°œ ì´ìƒì˜ ì€ë‹‰ì¸µ / ì¶œì²˜: /content/drive/MyDrive/á„€á…¡á†¼á„‹á…´ á„Œá…¡á„…á…­/[á„‹á…µá„‰á…²á„…á…µá„‘á…©á„á…³ 2022-2á„’á…©] á„’á…§á†¨á„‰á…µá†«á„‰á…¥á†¼á„Œá…¡á†¼ á„Œá…¥á†¼á„á…¢á†¨á„€á…³á†·á„‹á…²á†¼ á„ƒá…©á†¼á„’á…£á†¼.pdf - 8 
    
    
    ì£¼ì–´ì§„ ê·¼ê±°: í˜ì‹ ì„±ì¥ ì •ì±…ê¸ˆìœµ ë™í–¥ : ICT ì‚°ì—…ì„ ì¤‘ì‹¬ìœ¼ë¡œ
      CISì´ìŠˆë¦¬í¬íŠ¸ 2022-2 í˜¸ | 3 |1. ë“¤ì–´ê°€ë©°
    â–¶í˜ì‹ ì„±ì¥ ì •ì±…ê¸ˆìœµê¸°ê´€ì€ ê±´ê°•í•œ í˜ì‹ ì‚°ì—… ìƒíƒœê³„ë¥¼ ì¡°ì„±í•˜ê¸° ìœ„í•´ ê¸°ì—… ì„±ì¥ì— í•„ìš”í•œ ìê¸ˆì„ 
    ì§€ì›í•˜ëŠ” í˜ì‹ ì„±ì¥ ì •ì±…ê¸ˆìœµ ì œë„ë¥¼ ì‹œí–‰í•˜ê³  ìˆìŒ
    ï¿®í˜ì‹ ì„±ì¥ ì •ì±…ê¸ˆìœµê¸°ê´€ì€ í˜ì‹ ì„±ì¥ì— ëŒ€í•œ ì •ì˜ë¥¼ êµ¬ì²´í™”í•œ ì •ì±…ê¸ˆìœµ ê°€ì´ë“œë¼ì¸*ì— ë”°ë¼ í˜ì‹ ì„±ì¥  
    ì‚°ì—…ìœ¡ì„±ì„ ìœ„í•œ ì •ì±…ê¸ˆìœµ ì—…ë¬´ë¥¼ ì¶”ì§„ ì¤‘ì„
           * í˜ì‹ ì„±ì¥ ê¸°ì—…ë°œêµ´ ë° ê¸ˆìœµì§€ì›ì„ ìœ„í•´ í™œìš©í•˜ëŠ” ê¸°ì¤€ìœ¼ë¡œ , â€˜9ëŒ€ í…Œë§ˆ-46ê°œ ë¶„ì•¼-296ê°œ í’ˆëª©â€™ìœ¼ë¡œ êµ¬ì„±
    â–¶í˜ì‹ ì„±ì¥ ì •ì±…ê¸ˆìœµ ì œë„ ì‹œí–‰ ì´í›„ ê³µê¸‰ ê·œëª¨ê°€ ë§¤ë…„ ì¦ê°€í•˜ëŠ” ë“±, ë¯¸ë˜ í˜ì‹ ì„±ì¥ ë¶„ì•¼ì˜ ê¸€ë¡œë²Œ 
    ê²½ìŸë ¥ í™•ë³´ë¥¼ ìœ„í•œ ê¸ˆìœµì§€ì›ì´ ì§€ì† ì¶”ì§„ ì¤‘ì„
    ï¿®ì •ì±…ê¸ˆìœµê¸°ê´€ì˜ í˜ì‹ ì„±ì¥ ë¶„ì•¼ ì •ì±…ê¸ˆìœµ ê³µê¸‰ê·œëª¨ëŠ” 2017ë…„ 240,787 ì–µ ì›ì—ì„œ  ì—°í‰ê·   37.2% ì¦ê°€
    í•˜ì—¬ 2021 ë…„ 854,338 ì–µ ì›ì— ì´ë¥´ëŠ” ë“± ê·¸ ì™¸ì—°ì„ í™•ì¥í•´ë‚˜ê°€ê³  ìˆìŒ / ì¶œì²˜: /content/drive/MyDrive/á„€á…¡á†¼á„‹á…´ á„Œá…¡á„…á…­/[á„‹á…µá„‰á…²á„…á…µá„‘á…©á„á…³ 2022-2á„’á…©] á„’á…§á†¨á„‰á…µá†«á„‰á…¥á†¼á„Œá…¡á†¼ á„Œá…¥á†¼á„á…¢á†¨á„€á…³á†·á„‹á…²á†¼ á„ƒá…©á†¼á„’á…£á†¼.pdf - 2 
    
    
    
    ë‹µë³€: 
    [ANSWER:
    ì˜ˆ, í˜ì‹ ì„±ì¥ ì •ì±… ê¸ˆìœµì—ì„œ ì¸ê³µì§€ëŠ¥ì€ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. í˜ì‹ ì„±ì¥ ì •ì±… ê¸ˆìœµì€ ê±´ê°•í•œ í˜ì‹ ì‚°ì—… ìƒíƒœê³„ë¥¼ ì¡°ì„±í•˜ê¸° ìœ„í•´ ê¸°ì—… ì„±ì¥ì— í•„ìš”í•œ ìê¸ˆì„ ì§€ì›í•˜ëŠ” í˜ì‹ ì„±ì¥ ì •ì±… ê¸ˆìœµ ì œë„ë¥¼ ì‹œí–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. í˜ì‹ ì„±ì¥ ì •ì±… ê¸ˆìœµê¸°ê´€ì€ í˜ì‹ ì„±ì¥ì— ëŒ€í•œ ì •ì˜ë¥¼ êµ¬ì²´í™”í•œ ì •ì±…ê¸ˆìœµ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ í˜ì‹ ì„±ì¥ ì‚°ì—… ìœ¡ì„±ì„ ìœ„í•œ ì •ì±…ê¸ˆìœµ ì—…ë¬´ë¥¼ ì¶”ì§„í•˜ê³  ìˆìŠµë‹ˆë‹¤. í˜ì‹ ì„±ì¥ ì •ì±… ê¸ˆìœµì—ì„œ ì¸ê³µì§€ëŠ¥ì€ 9ëŒ€ í…Œë§ˆ, 46ê°œ ë¶„ì•¼, 296ê°œ í’ˆëª©ìœ¼ë¡œ êµ¬ì„±ëœ í˜ì‹ ì„±ì¥ ì‚°ì—… ìœ¡ì„±ì˜ í•µì‹¬ ë¶„ì•¼ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. í˜ì‹ ì„±ì¥ ì •ì±… ê¸ˆìœµê¸°ê´€ì€ í˜ì‹ ì„±ì¥ ë¶„ì•¼ ì •ì±…ê¸ˆìœµ ê³µê¸‰ ê·œëª¨ë¥¼ ë§¤ë…„ ì¦ê°€ì‹œì¼œ ë¯¸ë˜ í˜ì‹ ì„±ì¥ ë¶„ì•¼ì˜ ê¸€ë¡œë²Œ ê²½ìŸë ¥ì„ í™•ë³´í•˜ê¸° ìœ„í•œ ê¸ˆìœµ ì§€ì›ì„ ì§€ì†í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    

# Reference
[ëª¨ë‘ì˜ AI - https://www.youtube.com/@AI-km1yn](https://www.youtube.com/@AI-km1yn)
